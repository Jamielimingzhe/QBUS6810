{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d2f722-74ad-451d-8b9f-5b974c368aa3",
   "metadata": {},
   "source": [
    "# <font color = '#e64626'><center>QBUS6810 Group Assignment</center></font>\n",
    "### <center>Group 18: 490347812, , , , , </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584136f9-e7ef-4fd7-966c-1b03d1bfb963",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data Processing](#data_processing)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "3. [Feature Engineering](#feature_engineering)\n",
    "4. [Methodology](#methodology)\n",
    "<br> 4.1 [Model 1: *model name*](#model_1)\n",
    "<br> 4.2 [Model 2: *model name*](#model_2)\n",
    "<br> 4.3 [Model 3: *model name*](#model_3)\n",
    "<br> 4.4 [Model 4: *model name*](#model_4)\n",
    "<br> 4.5 [Model 5: *model name*](#model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6a19c0-036b-40fe-abf5-363a84ee84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import geopandas as gpd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression,RidgeCV, Ridge,LassoCV, Lasso,ElasticNetCV, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# import nltk\n",
    "# import ast\n",
    "# from nltk.tokenize import word_tokenize as wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ece2b42-3683-479a-9dc0-bdc31293fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = {\"xtick.labelsize\": 12, \"ytick.labelsize\": 12, \"axes.labelsize\": 15, \n",
    "      \"axes.titlesize\": 15, \"legend.fontsize\": 12}\n",
    "sns.set_context(\"notebook\", rc=rc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0819f-19be-4ea4-ad81-43df63775042",
   "metadata": {},
   "source": [
    "## <font color = '#e64626'><a id='data_processing'>1. Data Processing</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a06e288-751e-422c-a0a5-7ab5dee708e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train/test data and combine to form a 6000-row dataframe to ensure they are both processed the same way\n",
    "train_4000 = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.concat([train_4000,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "# Dropping unnecessary features\n",
    "train = train.drop(['neighborhood_overview','host_location','host_neighbourhood','neighbourhood'],axis=1)\n",
    "\n",
    "# Convert host start date to numbers of days as host\n",
    "train['Host_Days'] = ((pd.to_datetime('2022-11-01') - pd.to_datetime(train['host_since'],infer_datetime_format=True))/np.timedelta64(1, 'D')).astype('int')\n",
    "\n",
    "# Convert strings to floats\n",
    "train[\"host_response_rate\"] = train[\"host_response_rate\"].str.rstrip('%').astype('float') / 100.0\n",
    "train[\"host_acceptance_rate\"] = train[\"host_acceptance_rate\"].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "# Fill host_response_time NAs with \"Others\"\n",
    "train[\"host_response_time\"] = train[\"host_response_time\"].fillna('Others')\n",
    "\n",
    "# Convert host related dummies\n",
    "host_dummies = pd.get_dummies(train[[\"host_response_time\",\"host_is_superhost\",\"host_identity_verified\",\"instant_bookable\"]],drop_first=True)\n",
    "\n",
    "# Convert type related dummies\n",
    "type_dummies = pd.get_dummies(train[['property_type','room_type']],drop_first=True)\n",
    "\n",
    "#Convert location dummies\n",
    "location = pd.get_dummies(train['neighbourhood_cleansed'])\n",
    "\n",
    "# Convert host_verifications from string to list then counted the number of element to form host_verifications_counts\n",
    "train[\"host_verifications_clean\"] = train['host_verifications'].astype('object')\n",
    "for i in range(len(train[\"host_verifications\"])):\n",
    "    if train.loc[i,\"host_verifications\"] == \"[]\":\n",
    "        train.at[i,\"host_verifications_clean\"] = []\n",
    "    else:\n",
    "        train.at[i,\"host_verifications_clean\"] = train.loc[i,\"host_verifications\"][2:-2].split(\"', '\")  \n",
    "train['host_verifications_counts'] = [len(i) for i in train[\"host_verifications_clean\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Combine longitude and latitude\n",
    "long_lat = train[['longitude','latitude']]\n",
    "\n",
    "\n",
    "host_numbers = pd.concat([train[['host_verifications_counts','host_response_rate',\n",
    "                                 'host_acceptance_rate','Host_Days','maximum_nights','minimum_nights']],\n",
    "                          np.log(train['host_listings_count'])],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "review_scores = train[['review_scores_rating','review_scores_accuracy','review_scores_cleanliness',\n",
    "                       'review_scores_checkin','review_scores_communication','review_scores_location',\n",
    "                       'review_scores_value']]\n",
    "\n",
    "review_numbers = np.log(train[['number_of_reviews','reviews_per_month']])\n",
    "\n",
    "# Extract and Log the training prices\n",
    "y = train['price'][:4000]\n",
    "y_train_log = np.log(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2a3eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_type =train['property_type']\n",
    "# property_type_dummy = np.select(condlist=[p_type.str.contains('Private', case=False),\n",
    "#                                           p_type.str.contains('entire', case=False)],\n",
    "#                                           choicelist=['Private', 'Entire'],default='others')\n",
    "# property_type_dummy=pd.get_dummies(property_type_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991be651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['amenities_clean'] = np.nan\n",
    "train['amenities_clean'] = train['amenities_clean'].astype('object')\n",
    "\n",
    "for i in tqdm(range(len(train['amenities']))):\n",
    "    train.at[i,'amenities_clean'] = train.loc[i,'amenities'][2:-2].split('\", \"')\n",
    "    \n",
    "for i in tqdm(range(len(train['amenities_clean']))):\n",
    "    for j in range(len(train.loc[i,'amenities_clean'])):\n",
    "        if 'Fast wifi \\\\u2013' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Fast Wifi'\n",
    "        if 'Wifi \\\\u2013' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Wifi'\n",
    "        if 'HDTV' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'HD Television'\n",
    "        if 'TV' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'TV'\n",
    "        if 'body soap' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Body soap'\n",
    "        if 'shampoo' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Shampoo'\n",
    "        if 'refrigerator' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Refrigerator'\n",
    "        if 'fridge' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Refrigerator'\n",
    "        if 'conditioner' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Conditioner'\n",
    "        if 'stove' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Stove'\n",
    "        if 'oven' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Oven'\n",
    "        if 'sound system' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Sound system'\n",
    "        if 'Sound system' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Sound system'\n",
    "        if 'Clothing storage' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Clothing storage'\n",
    "        if 'Children\\\\u2019s books and toys' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Children\\\\u2019s books and toys'\n",
    "        if 'Shared hot tub' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Hot tub'\n",
    "        if 'Private hot tub' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private hot tub'\n",
    "        if 'Shared pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Pool'\n",
    "        if 'Shared indoor pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Pool'\n",
    "        if 'Shared outdoor pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Pool'\n",
    "        if 'Private pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private pool'\n",
    "        if 'Private indoor pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private pool'\n",
    "        if 'Private outdoor pool' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private pool'\n",
    "        if 'Free washer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Washer'\n",
    "        if 'Paid washer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Paid Washer'\n",
    "        if 'Washer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Washer'\n",
    "        if 'Dryer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Dryer'\n",
    "        if 'Free dryer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Dryer'\n",
    "        if 'Paid dryer' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Paid Dryer'\n",
    "        if 'on premises' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Parking on premises'\n",
    "        if 'off premises' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Parking off premises'\n",
    "        if 'Free street parking' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Parking off premises'\n",
    "        if 'conditioning' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Air conditioning'\n",
    "        if 'Game console' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Game console'\n",
    "        if 'Gym' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Gym'\n",
    "        if 'gym' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Gym'\n",
    "        if 'coffee' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Coffee maker'\n",
    "        if 'sauna' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Sauna'\n",
    "        if 'high chair' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'High chair'\n",
    "        if 'High chair' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'High chair'\n",
    "        if 'crib' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Crib'\n",
    "        if 'Crib' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Crib'\n",
    "        if 'Fenced garden or backyard' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private garden or backyard'\n",
    "        if 'Private fenced garden or backyard' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private garden or backyard'\n",
    "        if 'Shared fenced garden or backyard' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Shared garden or backyard'\n",
    "        if 'Private fenced garden or backyard' in train.loc[i,'amenities_clean'][j]:\n",
    "            train.loc[i,'amenities_clean'][j] = 'Private garden or backyard'\n",
    "        \n",
    "amen_list = train['amenities_clean'].to_list()\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "bow = vectorizer.fit_transform(amen_list)\n",
    "bow_df = pd.DataFrame(bow.todense(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_des = [i for i in train['description']]\n",
    "count_vectorizer = CountVectorizer(binary=True)\n",
    "count_vectorizer.fit(corpus_des)\n",
    "features = count_vectorizer.transform(corpus_des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cafea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_index = count_vectorizer.get_feature_names_out().tolist().index('beach')\n",
    "beach = np.array(features[:, beach_index].todense()).reshape(-1)\n",
    "beach = pd.DataFrame(beach, columns=['beach_dummy'])\n",
    "\n",
    "apartment_index = count_vectorizer.get_feature_names_out().tolist().index('city')\n",
    "apartment = np.array(features[:, apartment_index].todense()).reshape(-1)\n",
    "apartment = pd.DataFrame(apartment, columns=['city_dummy'])\n",
    "\n",
    "walk_index = count_vectorizer.get_feature_names_out().tolist().index('bondi')\n",
    "walk = np.array(features[:, walk_index].todense()).reshape(-1)\n",
    "walk = pd.DataFrame(walk, columns=['walk_dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf7843",
   "metadata": {},
   "source": [
    "### 2.3 Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72997f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['description'].isna(),'description'] = ''\n",
    "# train.loc[train['neighborhood_overview'].isna(),'neighborhood_overview'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"host_response_rate\"] = train[\"host_response_rate\"].fillna(0)\n",
    "train[\"host_acceptance_rate\"] = train[\"host_acceptance_rate\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79ff7672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883620</td>\n",
       "      <td>0.878256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.883620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0.878256</td>\n",
       "      <td>0.834538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accommodates  bedrooms      beds\n",
       "accommodates      1.000000  0.883620  0.878256\n",
       "bedrooms          0.883620  1.000000  0.834538\n",
       "beds              0.878256  0.834538  1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check correlation between accommodates,bedrooms and beds\n",
    "accomm_data_temp = train[['accommodates','bedrooms','beds']].dropna()\n",
    "accomm_data_temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "313dc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using accommodates to predict missing bedrooms and beds\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(np.array(accomm_data_temp['accommodates']).reshape(-1, 1), accomm_data_temp['bedrooms'])\n",
    "train.loc[train['bedrooms'].isna(),'bedrooms'] = linear_reg.predict(np.array(train.loc[train['bedrooms'].isna(),'accommodates']).reshape(-1, 1)).round(0).astype('int')\n",
    "\n",
    "linear_reg.fit(np.array(accomm_data_temp['accommodates']).reshape(-1, 1), accomm_data_temp['beds'])\n",
    "train.loc[train['beds'].isna(),'beds'] = linear_reg.predict(np.array(train.loc[train['beds'].isna(),'accommodates']).reshape(-1, 1)).round(0).astype('int')\n",
    "\n",
    "acc_room_bed = np.log(train[['accommodates','bedrooms','beds']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46204b-fdd5-4acc-a057-6248a390e13c",
   "metadata": {},
   "source": [
    "## <font color = '#e64626'><a id='eda'>2. Exploratory Data Analysis</a></font>\n",
    "\n",
    "The example provided here is to show you how to save figures of an appropriate resolution by using <tt>dpi</tt>. The <tt>bbox_inches='tight'</tt> is used to ensure that when your figure is saved, there are no cropping issues. In the example, the figure is saved as a <tt>.png</tt>, but you may also want to save your figures as a <tt>.pdf</tt>.\n",
    "\n",
    "When you produce figures, make sure that all axes labels are readable. This notebook has been setup so that in general, the fontsizes are readable. These are defined in cell [2].\n",
    "\n",
    "You can change the dimensions of the figure by changing the `figsize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2050671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Missing Values\n",
       "description                        2\n",
       "host_response_time               184\n",
       "host_response_rate               184\n",
       "host_acceptance_rate             137\n",
       "bedrooms                         392\n",
       "beds                              33"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display columns with missing values\n",
    "df_null_count = 6000 - train.count()\n",
    "pd.DataFrame(df_null_count[df_null_count!=0][1:],columns=['Missing Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8508555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both Rate Seems to have no relationship with price, they are dropped\n",
    "# plt.scatter(train[\"host_response_rate\"],y_train_log)\n",
    "# plt.scatter(train[\"host_acceptance_rate\"],y_train_log)\n",
    "# plt.scatter(train[\"host_listings_count\"],y_train_log)\n",
    "# plt.scatter(train['Host_Days'][:4000],y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e867c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train[\"review_scores_value\"][:4000],y_train_log)\n",
    "plt.xlim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f289a-a570-4d0a-8a91-ee2b784fa16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(y, bins=100);\n",
    "plt.xlabel('Price (AUD)')\n",
    "plt.ylabel('Number of listings')\n",
    "plt.savefig('hist_of_response.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be344915",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train[['review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value']].corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade9a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e03b45d-52a3-47b7-aa05-76312ebdeb44",
   "metadata": {},
   "source": [
    "## <font color = '#e64626'><a id='feature_engineering'>3. Feature Engineering</a></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00688a12",
   "metadata": {},
   "source": [
    "### Mapping Coordinates to Statistical Area 2 for more precision than neibourbood_cleased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc75fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sydney = gpd.read_file('SA2_sydney/sydney_SA2.shp')\n",
    "# sydney['region'] = sydney['geometry']\n",
    "# geo_train = gpd.GeoDataFrame(train, geometry=gpd.points_from_xy(train.longitude, train.latitude))\n",
    "# sydney.crs = \"EPSG:7844\"\n",
    "# geo_train.crs = \"EPSG:7844\"\n",
    "# geo_train_join = gpd.tools.sjoin(geo_train, sydney[['SA2_NAME21','geometry','region']], predicate=\"within\", how='left')\n",
    "\n",
    "# geo_nan = geo_train_join[geo_train_join['SA2_NAME21'].isna()][['latitude','longitude']]\n",
    "# geo_nan = gpd.GeoDataFrame(geo_nan, geometry=gpd.points_from_xy(geo_nan.longitude, geo_nan.latitude))\n",
    "# geo_nan.crs = \"EPSG:7844\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1b899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in geo_nan.index:\n",
    "#     geo_train_join.loc[i,'SA2_NAME21'] = sydney.loc[sydney.distance(geo_nan.loc[i,'geometry']).sort_values().index[0],'SA2_NAME21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = pd.get_dummies(geo_train_join['SA2_NAME21'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo_plot_df = pd.DataFrame(geo_train_join[:4000].groupby('SA2_NAME21').mean()['price'])\n",
    "# geo_plot_df['median'] = geo_train_join[:4000].groupby('SA2_NAME21').median()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56681ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sydney_plot = sydney.set_index('SA2_NAME21')\n",
    "# geo_plot = pd.concat([sydney_plot,np.log(geo_plot_df)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3122e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo_plot.plot(column='price',figsize=(20,10),legend=True,cmap='plasma',missing_kwds= dict(color = \"lightgrey\"))\n",
    "# plt.xlim(150.5,151.35)\n",
    "# plt.ylim(-34.2,-33)\n",
    "\n",
    "# # plt.xlim(150.88,151.35)\n",
    "# # plt.ylim(-34.1,-33.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae63d4-82f8-4303-a422-cd5e6bbf2d24",
   "metadata": {},
   "source": [
    "## <font color = '#e64626'><a id='methodology'>4. Methodology</a></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73bf77-7ecf-4b69-b527-2094c47fbf97",
   "metadata": {},
   "source": [
    "### <font color = '#e64626'><a id='model_1'>4.1. Model 1: OLS Lasso</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae055ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_features_all = pd.concat([beach,apartment,walk,host_dummies,host_numbers,acc_room_bed,\n",
    "                             review_scores,review_numbers,long_lat,location,type_dummies,bow_df],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(model1_features_all)\n",
    "model1_features_all_scaled = scaler.transform(model1_features_all)\n",
    "\n",
    "X_scaled = model1_features_all_scaled[:4000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y_train_log, test_size = 0.2)\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train);\n",
    "\n",
    "lasso = LassoCV(cv=5)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "best_lasso = Lasso(alpha=lasso.alpha_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff12529",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(model1_features_all.columns.values)\n",
    "\n",
    "n_coefs = 15\n",
    "model = [ols, lasso]\n",
    "model_name = ['OLS', 'Lasso']\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "for i in range(len(model)):\n",
    "    betas = model[i].coef_\n",
    "\n",
    "    indicies = np.argsort(np.abs(betas))[-n_coefs:]\n",
    "    top_predictors = np.array(predictors)[indicies]\n",
    "    top_betas = betas[indicies]\n",
    "\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.barh(top_predictors, top_betas, alpha=0.5, edgecolor='black')\n",
    "    sns.despine()\n",
    "    plt.xlabel('Beta coefficient')\n",
    "    plt.title(model_name[i]);\n",
    "plt.suptitle('Figure 5. Top {} Beta Coefficients'.format(n_coefs), fontsize = 16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929212d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [ols, lasso]\n",
    "model_name = ['OLS', 'Lasso']\n",
    "p = len(predictors)\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "for i in range(len(model)):\n",
    "    plt.subplot(len(model), 1, i+1)\n",
    "    plt.bar(np.arange(p), model[i].coef_, width=1, alpha=0.5, edgecolor = 'black')\n",
    "    plt.xticks([])\n",
    "    plt.xlim([-1.5, p+0.5])\n",
    "    plt.ylim([-0.1, 0.2])\n",
    "    plt.ylabel(model_name[i] + '\\nBeta Coefficient')\n",
    "plt.xticks([0, 50, 100, 150])\n",
    "plt.xlabel('Predictor Number')\n",
    "plt.suptitle('Figure 6. Comparison of all Beta Coefficients', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71184244",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['RMSE', 'R2'])\n",
    "\n",
    "ols = LinearRegression()\n",
    "y_pred = cross_val_predict(ols, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "# OLS sometimes makes crazy predictions so we clip them to something sensible\n",
    "y_pred = np.clip(y_pred, y_train.min(), y_train.max())\n",
    "\n",
    "rmse = mean_squared_error(np.exp(y_train), np.exp(y_pred), squared=False)\n",
    "r2 = r2_score(np.exp(y_train), np.exp(y_pred))\n",
    "\n",
    "results.loc['OLS'] = rmse, r2\n",
    "\n",
    "y_pred = cross_val_predict(best_lasso, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "rmse = mean_squared_error(np.exp(y_train), np.exp(y_pred), squared=False)\n",
    "r2 = r2_score(np.exp(y_train), np.exp(y_pred))\n",
    "\n",
    "results.loc['Lasso'] = rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527103d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16023d6c-c915-454e-806f-cbac831f83df",
   "metadata": {},
   "source": [
    "Now we need to generate the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef81f3-e305-42b7-8dad-bc728908f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso.fit(X_scaled,y_train_log)\n",
    "\n",
    "id_col = np.arange(2000).reshape(-1, 1)\n",
    "y_pred = np.exp(best_lasso.predict(model1_features_all_scaled[4000:]).reshape(-1, 1))\n",
    "\n",
    "data = np.hstack((id_col, y_pred))\n",
    "\n",
    "m1_submission = pd.DataFrame(data, columns=['id', 'price'])\n",
    "m1_submission['id'] = m1_submission['id'].astype('int')\n",
    "\n",
    "# m1_submission.to_csv('model1_Lasso_scaled_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c5455-5050-42f7-a133-982d0ca7657f",
   "metadata": {},
   "source": [
    "### <font color = '#e64626'><a id='model_2'>4.2. Model 2: *model name*</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y_train_log, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor=XGBRegressor(eval_metric='rmse')\n",
    "# param_grid = {\"max_depth\":    [6],\n",
    "#               \"n_estimators\": [800],\n",
    "#               \"learning_rate\": [0.015],\n",
    "#              'min_child_weight':[0.75]}\n",
    "# search = GridSearchCV(regressor, param_grid, cv=5).fit(X_train, y_train)\n",
    "# xgb=XGBRegressor(learning_rate = search.best_params_[\"learning_rate\"],\n",
    "#                            n_estimators  = search.best_params_[\"n_estimators\"],\n",
    "#                            max_depth     = search.best_params_[\"max_depth\"],\n",
    "#                sampling_method= 'gradient_based',subsample=0.1,tree_method='gpu_hist',\n",
    "#                  objective='reg:squarederror',booster='gbtree',reg_lambda=0,reg_alpha=0, n_jobs=4,\n",
    "#                  process_type='default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31e0fa-1595-437b-bd28-a17b98dd6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate = 0.015, n_estimators = 800, max_depth = 6,min_child_weight= 0.75,\n",
    "                   sampling_method = 'gradient_based', subsample=0.1,tree_method='gpu_hist', \n",
    "                   objective='reg:squarederror',booster='gbtree',reg_lambda=0,reg_alpha=0, n_jobs=4,process_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be15bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717970e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.exp(xgb.predict(model1_features_all_scaled[4000:]).reshape(-1, 1))\n",
    "\n",
    "# data = np.hstack((id_col, y_pred))\n",
    "# m2_submission = pd.DataFrame(data, columns=['id', 'price'])\n",
    "# m2_submission['id'] = m2_submission['id'].astype('int')\n",
    "\n",
    "# m2_submission.to_csv('model2_XGBoost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d2892-d6e3-4c1c-8743-1420a9c1884e",
   "metadata": {},
   "source": [
    "### <font color = '#e64626'><a id='model_3'>4.2. Model 3: *Random Forrest*</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y_train_log, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19357435-773a-49d4-9bde-b15f2539093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'min_samples_leaf': [5],\n",
    "    'max_features': [100],\n",
    "    'n_estimators': [600,700,800]\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(model, tuning_parameters, cv=5, return_train_score=False, n_jobs=4)\n",
    "rf_cv.fit(X_train_scaled,y_train)\n",
    "rf = rf_cv.best_estimator_\n",
    "\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7002ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled,y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41344e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_scaled,y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(rf.predict(model1_features_all_scaled[4000:]).reshape(-1, 1))\n",
    "\n",
    "data = np.hstack((id_col, y_pred))\n",
    "m3_submission = pd.DataFrame(data, columns=['id', 'price'])\n",
    "m3_submission['id'] = m3_submission['id'].astype('int')\n",
    "\n",
    "# m3_submission.to_csv('model3_Random_Forrest_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66706f1a-24b1-4360-bb4b-cfd5320c74e1",
   "metadata": {},
   "source": [
    "### <font color = '#e64626'><a id='model_4'>4.2. Model 4: *gb_Boost*</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496ca08-c337-4bdd-9bba-ea82811f509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate=0.05, max_depth=2, n_estimators=2000, subsample=0.5)\n",
    "gb.fit(X_scaled,y_train_log);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "\n",
    "importance = 100*(gb.feature_importances_/np.max(gb.feature_importances_))\n",
    "feature_importance = pd.Series(importance, index=predictors).sort_values(ascending=True)\n",
    "\n",
    "plt.barh(np.arange(p), feature_importance[-p:])\n",
    "plt.yticks(np.arange(p), feature_importance[-p:].index)\n",
    "plt.xlabel('% of maximum importance')\n",
    "plt.title('Figure 2. Variable importance of top {} predictors'.format(p));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.score(X_scaled,y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d280336",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(gb.predict(model1_features_all_scaled[4000:]).reshape(-1, 1))\n",
    "\n",
    "data = np.hstack((id_col, y_pred))\n",
    "m4_submission = pd.DataFrame(data, columns=['id', 'price'])\n",
    "m4_submission['id'] = m4_submission['id'].astype('int')\n",
    "\n",
    "# m4_submission.to_csv('model4_Gradient_Boost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2fc10-ab23-4a93-804a-12381f8d4a8d",
   "metadata": {},
   "source": [
    "### <font color = '#e64626'><a id='mode_5'>4.2. Model 5: *Model Stack*</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60a312-2f10-40d1-9c49-4d57734a6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Lasso', best_lasso), ('Random Forest', rf), ('Gradient Boost', gb)]\n",
    "\n",
    "stack = StackingRegressor(models, final_estimator=LinearRegression(positive=True), cv=5, n_jobs=4)\n",
    "stack.fit(X_scaled,y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(len(models)), stack.final_estimator_.coef_)\n",
    "plt.yticks(np.arange(len(models)), ['Lasso', 'Random Forest', 'Gradient Boost'])\n",
    "plt.xlabel('Model coefficient')\n",
    "plt.title('Figure 4. Model coefficients for our stacked model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(stack.predict(model1_features_all_scaled[4000:]).reshape(-1, 1))\n",
    "\n",
    "data = np.hstack((id_col, y_pred))\n",
    "m5_submission = pd.DataFrame(data, columns=['id', 'price'])\n",
    "m5_submission['id'] = m5_submission['id'].astype('int')\n",
    "\n",
    "# m5_submission.to_csv('model5_Stack_Lasso_RF_GB_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack test & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c553333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y_train_log, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30eeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Lasso', best_lasso), ('Random Forest', rf), ('Gradient Boost', gb)]\n",
    "\n",
    "stack = StackingRegressor(models, final_estimator=LinearRegression(positive=True), cv=5, n_jobs=4)\n",
    "stack.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54523579",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.arange(len(models)), stack.final_estimator_.coef_)\n",
    "plt.yticks(np.arange(len(models)), ['Lasso', 'Random Forest', 'Gradient Boost'])\n",
    "plt.xlabel('Model coefficient')\n",
    "plt.title('Figure 4. Model coefficients for our stacked model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96022769",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13396e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
